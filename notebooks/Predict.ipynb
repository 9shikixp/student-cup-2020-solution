{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "maketrans = str.maketrans\n",
    "import math\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import cuda\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel, RobertaTokenizer, RobertaConfig\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seed 固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed_value):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed = 13\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../processed_data/test_df_topic_theta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = '[' + test_df.topic_id.map(str).values + '] </s> ' + test_df.description.values\n",
    "\n",
    "test_X = np.array(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JobModel, self).__init__()\n",
    "        \n",
    "        config = RobertaConfig.from_pretrained(\n",
    "            'roberta-base', output_hidden_states=True)    \n",
    "        self.roberta = RobertaModel.from_pretrained(\n",
    "            'roberta-base', config=config)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 4, bias=False)\n",
    "        self.topic_classifier = nn.Linear(config.hidden_size, 20, bias=False)\n",
    "        nn.init.normal_(self.classifier.weight, std=0.02)\n",
    "        nn.init.normal_(self.topic_classifier.weight, std=0.02)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task_id):\n",
    "        _, _, hs = self.roberta(input_ids, attention_mask)\n",
    "        x = torch.stack([hs[-1][:, 0], hs[-2][:, 0], hs[-3][:, 0], hs[-4][:, 0]])\n",
    "        x = torch.mean(x, 0)\n",
    "        x = self.dropout(x)\n",
    "        if task_id == 0:\n",
    "            ret = self.classifier(x)\n",
    "        elif task_id == 1:\n",
    "            ret = self.topic_classifier(x)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../models/topic_tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "pred_all = []\n",
    "model = JobModel()\n",
    "model.roberta.resize_token_embeddings(len(tokenizer))\n",
    "device_id = 0\n",
    "model.to(device_id)\n",
    "# 訓練データの削り方によって，得られるモデルからの予測カテゴリ割合が大きく変わるので，\n",
    "# RoBERTa シングルモデルの学習時に，暫定スコアが最も高い提出に予測カテゴリ割合が近くなるようなseedの選択\n",
    "magic_seed = [42, 346, 291, 241, 312, 150, 353, 310, 266, 188]\n",
    "for s in magic_seed:\n",
    "    model.load_state_dict(torch.load('../models/roberta-10ens/roberta_mtdnn_ce5kl5_seed{}.model'.format(s)))\n",
    "    model.eval()\n",
    "    pred_ens = []\n",
    "    for i in range(0, len(test_X), batchsize):\n",
    "        text_batch = list(test_X[i:i+batchsize])\n",
    "        encoding = tokenizer(text_batch, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "        input_ids = encoding['input_ids'].to(device_id)\n",
    "        attention_mask = encoding['attention_mask'].to(device_id)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, task_id=0)\n",
    "        pred_y = F.softmax(outputs, dim=1).cpu().detach().numpy()\n",
    "\n",
    "        pred_ens += list(pred_y)\n",
    "    \n",
    "    pred_all += [pred_ens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission 作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = np.array(pred_all)\n",
    "logits = np.mean(pred_all, axis=0)\n",
    "test_y = logits.argmax(axis=1)\n",
    "test_y += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1743,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('../data/submit_sample.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[1] = test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (sub_df[1] == test_y).sum() == len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('../submission/roberta_mtdnn_ce5kl5_10ens_1088_magic_seed.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    0.335055\n",
       "3    0.281124\n",
       "1    0.235227\n",
       "2    0.148594\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[1].value_counts() / len(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    584\n",
       "3    490\n",
       "1    410\n",
       "2    259\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23522662, 0.14859438, 0.2811245 , 0.3350545 ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(list(Counter(sorted(test_y)).values())) / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gmvae",
   "language": "python",
   "name": "gmvae"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
